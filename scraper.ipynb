{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 dataset created Albury.csv\n",
      "2 dataset created BadgerysCreek.csv\n",
      "3 dataset created Cobar.csv\n",
      "4 dataset created CoffsHarbour.csv\n",
      "5 dataset created Moree.csv\n",
      "6 dataset created Newcastle.csv\n",
      "7 dataset created NorahHead.csv\n",
      "8 dataset created NorfolkIsland.csv\n",
      "9 dataset created Penrith.csv\n",
      "10 dataset created Richmond.csv\n",
      "11 dataset created Sydney.csv\n",
      "12 dataset created SydneyAirport.csv\n",
      "13 dataset created WaggaWagga.csv\n",
      "14 dataset created Williamtown.csv\n",
      "15 dataset created Wollongong.csv\n",
      "16 dataset created Canberra.csv\n",
      "17 dataset created Tuggeranong.csv\n",
      "18 dataset created MountGinini.csv\n",
      "19 dataset created Ballarat.csv\n",
      "20 dataset created Bendigo.csv\n",
      "21 dataset created Sale.csv\n",
      "22 dataset created MelbourneAirport.csv\n",
      "23 dataset created Melbourne.csv\n",
      "24 dataset created Mildura.csv\n",
      "25 dataset created Nhil.csv\n",
      "26 dataset created Portland.csv\n",
      "27 dataset created Watsonia.csv\n",
      "28 dataset created Dartmoor.csv\n",
      "29 dataset created Brisbane.csv\n",
      "30 dataset created Cairns.csv\n",
      "31 dataset created GoldCoast.csv\n",
      "32 dataset created Townsville.csv\n",
      "33 dataset created Adelaide.csv\n",
      "34 dataset created MountGambier.csv\n",
      "35 dataset created Nuriootpa.csv\n",
      "36 dataset created Woomera.csv\n",
      "37 dataset created Albany.csv\n",
      "38 dataset created Witchcliffe.csv\n",
      "39 dataset created PearceRAAF.csv\n",
      "40 dataset created PerthAirport.csv\n",
      "41 dataset created Perth.csv\n",
      "42 dataset created SalmonGums.csv\n",
      "43 dataset created Walpole.csv\n",
      "44 dataset created Hobart.csv\n",
      "45 dataset created Launceston.csv\n",
      "46 dataset created AliceSprings.csv\n",
      "47 dataset created Darwin.csv\n",
      "48 dataset created Katherine.csv\n",
      "49 dataset created Uluru.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "url='https://karki23.github.io/Weather-Data/assignment.html'\n",
    "website_url=requests.get(url).text\n",
    "URL='https://karki23.github.io/Weather-Data/'\n",
    "soup=BeautifulSoup(website_url,'html.parser')\n",
    "links=[]\n",
    "cities=[]\n",
    "for link in soup.findAll('a'):\n",
    "    links.append(URL+link.get('href'))\n",
    "    city=link.get('href')\n",
    "    cities.append(city.replace('.html',''))\n",
    "len_cities=len(cities)\n",
    "header=['Date','Location',' MinTemperature', 'MaxTemperature', 'Rainfall', 'Evaporation', 'Sunshine', 'WindGustDir', 'WindGustSpeed', 'WindDir9am', 'WindDir3pm', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm', 'RainToday', 'RISK_MM', 'RainTomorrow']\n",
    "for x in range(len(links)):\n",
    "    \n",
    "    city_url=requests.get(links[x]).text\n",
    "    soup_city=BeautifulSoup(city_url,'lxml')\n",
    "    rows=soup_city.findAll('tr')\n",
    "    dataset=[]\n",
    "    dataset.append(header)\n",
    "    cleantext=[]\n",
    "    for row in rows:\n",
    "        row_td=row.findAll('td')\n",
    "        str_cells=str(row_td)\n",
    "        cleantext=BeautifulSoup(str_cells,'lxml').get_text()\n",
    "        cleantext=cleantext.replace(']','')\n",
    "        cleantext=cleantext.replace('[','')\n",
    "        text=cleantext.split(',')\n",
    "        dataset.append(text)\n",
    "    del dataset[1]\n",
    "\n",
    "    filename=cities[x]+'.csv'\n",
    "    with open(filename,'a') as file:\n",
    "        file_writer=csv.writer(file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        for y in dataset:\n",
    "            file_writer.writerow(y)\n",
    "    file.close()\n",
    "    print(x+1,\"dataset created\",filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
